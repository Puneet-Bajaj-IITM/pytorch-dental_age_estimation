{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 classification 결과를 환자 단위, 파트 별 단위로 묶어서 결과 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENV SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type_3cls = '3classes'\n",
    "label_type_5cls = '5classes'\n",
    "learning_rate = '5e-5'\n",
    "\n",
    "num_fold = 5\n",
    "\n",
    "# true label env\n",
    "true_dataset_root = 'E:/Thesis_research/Database/Medical/Dental_directory_dataset'\n",
    "true_lbl_dir = os.path.join(true_dataset_root, 'ClassificationClass',label_type_3cls)\n",
    "\n",
    "# prediction env\n",
    "pred_root = f'E:/Thesis_research/results_materials/Dental/raw_prediction_results/{learning_rate}'\n",
    "\n",
    "exp_dir_3cls = os.path.join(pred_root, label_type_3cls)\n",
    "exp_dir_5cls = os.path.join(pred_root, label_type_5cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION SETTING AND VOTING\n",
    "\n",
    "* 각 네트워크 별로 4개의 part에 대한 prediction 중 unique 병록번호에 해당하는 prediction들을 모아서 voting해서 true와 비교!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current fold: 1\n",
      "Confusion matrix: \n",
      "[[ 72   7   0]\n",
      " [  3 193   5]\n",
      " [  0  12  35]]\n",
      "Overall accuracy =  0.9174311926605505\n",
      "\n",
      "Current fold: 2\n",
      "Confusion matrix: \n",
      "[[ 75   3   0]\n",
      " [  3 182   9]\n",
      " [  0   6  26]]\n",
      "Overall accuracy =  0.930921052631579\n",
      "\n",
      "Current fold: 3\n",
      "Confusion matrix: \n",
      "[[ 71   9   0]\n",
      " [  4 195   2]\n",
      " [  0   8  26]]\n",
      "Overall accuracy =  0.926984126984127\n",
      "\n",
      "Current fold: 4\n",
      "Confusion matrix: \n",
      "[[ 69  10   0]\n",
      " [  0 186  14]\n",
      " [  0   7  26]]\n",
      "Overall accuracy =  0.9006410256410257\n",
      "\n",
      "Current fold: 5\n",
      "Confusion matrix: \n",
      "[[ 66  14   0]\n",
      " [  1 187   8]\n",
      " [  0  11  39]]\n",
      "Overall accuracy =  0.8957055214723927\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "part_list = [16, 26, 36, 46]\n",
    "\n",
    "patient_wise_overall_acc_lst = []\n",
    "\n",
    "confusion_matrix_metric_tot_lst = []\n",
    "\n",
    "for i_fold_iter in range(num_fold):\n",
    "    print()\n",
    "    print(f'Current fold: {i_fold_iter +1 }')\n",
    "    \n",
    "    # ## TRUE LABEL SETTING\n",
    "    true_imageset_path = os.path.join(true_dataset_root,'ImageSets','Classification','eval' + str(i_fold_iter+1) + '.txt')\n",
    "    \n",
    "    with open(true_imageset_path, 'r') as f:\n",
    "         eval_img_list = f.read().split('\\n')\n",
    "\n",
    "    person_num_list =[]\n",
    "    for i_eval_img in eval_img_list:\n",
    "        if i_eval_img == '':\n",
    "            continue\n",
    "        eval_img_info = i_eval_img.split('_')\n",
    "        age_person_num = eval_img_info[0] + '_' + eval_img_info[1] # e.g. '20_2392392' because there are three miss labeled images file name\n",
    "        if len(eval_img_info)>1: # skip blank line\n",
    "            person_num_list.append(age_person_num)\n",
    "    person_num_unique_list, unique_idx = np.unique(np.array(person_num_list), return_index=True)\n",
    "    \n",
    "    person_num_perdiction_all_list = []\n",
    "    true_lbl_unique = []\n",
    "    \n",
    "    pred_dir_3cls = os.path.join(pred_root,label_type_3cls, f'resnet152-TL_aug-{label_type_3cls}-fold{i_fold_iter}','eval_result_resnet152_cls_best_model', 'prediction_class')\n",
    "    pred_result_list_3cls = sorted(os.listdir(pred_dir_3cls))\n",
    "    pred_dir_5cls = os.path.join(pred_root,label_type_5cls, f'resnet152-TL_aug-{label_type_5cls}-fold{i_fold_iter}','eval_result_resnet152_cls_best_model', 'prediction_class')\n",
    "    for i_iter, i_person_num_unique in enumerate(person_num_unique_list):\n",
    "        \n",
    "        pred_result_person_num = [s for s in pred_result_list_3cls if i_person_num_unique in s]\n",
    "        \n",
    "        # 하나라도 파트 없으면 false alarm!!\n",
    "        if not len(pred_result_person_num) == 4 :\n",
    "            print('Each person must have four teeth parts')\n",
    "            raise AssertionError\n",
    "            \n",
    "        # true label setting\n",
    "        true_lbl = 0\n",
    "        for i, i_pred in enumerate(pred_result_person_num):\n",
    "            true_lbl_path = os.path.join(true_lbl_dir, i_pred)\n",
    "            with open(true_lbl_path,'r') as f:\n",
    "                lbl = int(f.read())\n",
    "            if i==0:\n",
    "                true_lbl = lbl\n",
    "            else:\n",
    "                if true_lbl != lbl: # check all patients label is the same each other\n",
    "                    raise AssertionError\n",
    "                else:\n",
    "                    true_lbl = lbl\n",
    "        true_lbl_unique.append(true_lbl)\n",
    "            \n",
    "        person_num_prediction = []\n",
    "        for i_pred in pred_result_person_num:\n",
    "            pred_txt_nameOnly = os.path.splitext(i_pred)[0]\n",
    "            pred_name_info = pred_txt_nameOnly.split('_')\n",
    "            part_num = int(pred_name_info[-1])\n",
    "            \n",
    "            pred_result_3cls_path = os.path.join(pred_dir_3cls, i_pred)\n",
    "            with open(pred_result_3cls_path, 'r') as f:\n",
    "                pred_lbl_3cls = int(f.read())\n",
    "            person_num_prediction.append(pred_lbl_3cls)\n",
    "\n",
    "            pred_result_5cls_path = os.path.join(pred_dir_5cls, i_pred)\n",
    "            with open(pred_result_5cls_path, 'r') as f:\n",
    "                pred_lbl_5cls = int(f.read())\n",
    "            if pred_lbl_5cls in [1,2,3]:\n",
    "                pred_lbl_5cls = 1\n",
    "            elif pred_lbl_5cls == 4:\n",
    "                pred_lbl_5cls = 2\n",
    "            person_num_prediction.append(pred_lbl_5cls)\n",
    "            \n",
    "        person_num_perdiction_all_list.append(person_num_prediction)\n",
    "    \n",
    "    network_final_pred_list = []\n",
    "    for i_person_num_pred in person_num_perdiction_all_list:\n",
    "        most_common_pred, num_most_common_pred = Counter(i_person_num_pred).most_common(1)[0] # 4, 6 times\n",
    "        network_final_pred_list.append(most_common_pred)\n",
    "    \n",
    "    confusion_matrix_metric = confusion_matrix(true_lbl_unique, network_final_pred_list)\n",
    "    print('Confusion matrix: ')\n",
    "    print(confusion_matrix_metric)\n",
    "    confusion_matrix_metric_tot_lst.append(confusion_matrix_metric)\n",
    "    \n",
    "    overall_acc_metric = accuracy_score(true_lbl_unique, network_final_pred_list)\n",
    "    print('Overall accuracy = ', overall_acc_metric)\n",
    "    \n",
    "    patient_wise_overall_acc_lst.append(overall_acc_metric)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient wise cv 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[ 70.6   8.6   0. ]\n",
      " [  2.2 188.6   7.6]\n",
      " [  0.    8.8  30.4]]\n",
      "\n",
      "Overall Accuracy: \n",
      "acc:  0.9143365838779349\n",
      "std_error:  0.006258646357674501\n",
      "\n",
      "Group-wise accuracy: \n",
      "Age group 1\n",
      "acc:  0.891769717624148\n",
      "std_error:  0.02006584055648567\n",
      "\n",
      "Age group 2\n",
      "acc:  0.9505148442512873\n",
      "std_error:  0.0065296353469551345\n",
      "\n",
      "Age group 3\n",
      "acc:  0.7779531042591119\n",
      "std_error:  0.010156236908906872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: ')\n",
    "confusion_matrix_metric_tot = np.array(confusion_matrix_metric_tot_lst)\n",
    "confusion_matrix_metric_avg = np.mean(confusion_matrix_metric_tot, axis = 0)\n",
    "print(confusion_matrix_metric_avg)\n",
    "print()\n",
    "print('Overall Accuracy: ')\n",
    "patient_wise_avg_acc = np.mean(patient_wise_overall_acc_lst)\n",
    "patient_wise_std_error= np.std(patient_wise_overall_acc_lst) / np.sqrt(len(patient_wise_overall_acc_lst))\n",
    "print('acc: ',patient_wise_avg_acc)\n",
    "print('std_error: ', patient_wise_std_error)\n",
    "print()\n",
    "print('Group-wise accuracy: ')\n",
    "group_wise_acc_dict={}\n",
    "for i_group in range(confusion_matrix_metric_tot.shape[1]):\n",
    "    group_wise_acc_dict[i_group] = []\n",
    "    for i_fold in range(confusion_matrix_metric_tot.shape[0]):\n",
    "        confusion_matrix_cur = confusion_matrix_metric_tot[i_fold]\n",
    "        group_wise_acc = confusion_matrix_cur[i_group, i_group] / np.sum(confusion_matrix_cur[i_group, :])\n",
    "        group_wise_acc_dict[i_group].append(group_wise_acc)\n",
    "        \n",
    "    group_wise_acc_mean = np.mean(group_wise_acc_dict[i_group])\n",
    "    group_wise_acc_std_error = np.std(group_wise_acc_dict[i_group]) / np.sqrt(len(group_wise_acc_dict[i_group]))\n",
    "    print('Age group ' + str(i_group+1))\n",
    "    print('acc: ',group_wise_acc_mean)\n",
    "    print('std_error: ',group_wise_acc_std_error)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3cls part-wise와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== patient-wise =====\n",
      "(3cls + 5cls) voting vs 3cls patient-wise acc\n",
      "p-value 0.49414063152958787\n",
      "\n",
      "===== part-wise ======\n",
      "(3cls + 5cls) voting vs 3cls part 16 acc\n",
      "p-value 0.008440845954472493\n",
      "\n",
      "(3cls + 5cls) voting vs 3cls part 26 acc\n",
      "p-value 0.05656757821722401\n",
      "\n",
      "(3cls + 5cls) voting vs 3cls part 36 acc\n",
      "p-value 0.013973450006104386\n",
      "\n",
      "(3cls + 5cls) voting vs 3cls part 46 acc\n",
      "p-value 0.0047389854203696465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "print('====== patient-wise =====')\n",
    "print('(3cls + 5cls) voting vs 3cls patient-wise acc')\n",
    "patient_wise_acc_lst_3cls = np.load(os.path.join(exp_dir_3cls,'3cls_patient_wise_acc_lst.npy'))\n",
    "ttest,pval = ttest_ind(patient_wise_overall_acc_lst,patient_wise_acc_lst_3cls)\n",
    "print(\"p-value\",pval)\n",
    "print()\n",
    "\n",
    "print('===== part-wise ======')\n",
    "for i_part in part_list:\n",
    "    print('(3cls + 5cls) voting vs 3cls part ' + str(i_part) + ' acc')\n",
    "    part_wise_name = os.path.join(exp_dir_3cls, '3cls_part'+str(i_part)+'_acc_lst.npy')\n",
    "    part_wise_acc_lst = np.load(part_wise_name)\n",
    "    ttest,pval = ttest_ind(patient_wise_overall_acc_lst,part_wise_acc_lst)\n",
    "    print(\"p-value\",pval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5cls part-wise와 비교 (p-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== patient-wise =====\n",
      "(3cls + 5cls) voting vs 5cls patient-wise acc\n",
      "p-value 0.15717687963179283\n",
      "\n",
      "===== part-wise ======\n",
      "(3cls + 5cls) voting vs 5cls part 16 acc\n",
      "p-value 0.010623953765516905\n",
      "\n",
      "(3cls + 5cls) voting vs 5cls part 26 acc\n",
      "p-value 0.002901277540254535\n",
      "\n",
      "(3cls + 5cls) voting vs 5cls part 36 acc\n",
      "p-value 0.022206565962268235\n",
      "\n",
      "(3cls + 5cls) voting vs 5cls part 46 acc\n",
      "p-value 0.0060579472586501735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('====== patient-wise =====')\n",
    "print('(3cls + 5cls) voting vs 5cls patient-wise acc')\n",
    "patient_wise_acc_lst_5cls = np.load(os.path.join(exp_dir_5cls, '5cls_patient_wise_acc_lst.npy'))\n",
    "ttest,pval = ttest_ind(patient_wise_overall_acc_lst,patient_wise_acc_lst_5cls, equal_var=False)\n",
    "print(\"p-value\",pval)\n",
    "print()\n",
    "\n",
    "print('===== part-wise ======')\n",
    "for i_part in part_list:\n",
    "    print('(3cls + 5cls) voting vs 5cls part ' + str(i_part) + ' acc')\n",
    "    part_wise_name = os.path.join(exp_dir_5cls, '5cls_part'+str(i_part)+'_acc_lst.npy')\n",
    "    part_wise_acc_lst = np.load(part_wise_name)\n",
    "    ttest,pval = ttest_ind(patient_wise_overall_acc_lst,part_wise_acc_lst, equal_var=False)\n",
    "    print(\"p-value\",pval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare 3 cls and 5 cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== patient-wise =====\n",
      "3cls voting vs 5cls voting acc\n",
      "p-value 0.5178819509214782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('====== patient-wise =====')\n",
    "print('3cls voting vs 5cls voting acc')\n",
    "patient_wise_acc_lst_3cls = np.load(os.path.join(exp_dir_3cls, '3cls_patient_wise_acc_lst.npy'))\n",
    "patient_wise_acc_lst_5cls = np.load(os.path.join(exp_dir_5cls, '5cls_patient_wise_acc_lst.npy'))\n",
    "ttest,pval = ttest_ind(patient_wise_acc_lst_5cls,patient_wise_acc_lst_3cls)\n",
    "print(\"p-value\",pval)\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
