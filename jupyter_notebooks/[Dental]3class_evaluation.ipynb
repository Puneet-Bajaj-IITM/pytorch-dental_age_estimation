{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 classification 결과를 환자 단위, 파트 별 단위로 묶어서 결과 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENV SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = '3classes'\n",
    "learning_rate = '5e-5'\n",
    "\n",
    "# true label env\n",
    "true_dataset_root = 'E:/Thesis_research/Database/Medical/Dental_directory_dataset'\n",
    "true_lbl_dir = os.path.join(true_dataset_root, 'ClassificationClass',label_type)\n",
    "\n",
    "# prediction env\n",
    "pred_root = f'E:/Thesis_research/results_materials/Dental/raw_prediction_results/{learning_rate}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION SETTING AND VOTING\n",
    "\n",
    "* 각 네트워크 별로 4개의 part에 대한 prediction 중 unique 병록번호에 해당하는 prediction들을 모아서 voting해서 true와 비교!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current:  resnet152-TL_aug-3classes-fold0\n",
      "Confusion matrix: \n",
      "[[ 70   9   0]\n",
      " [  2 193   6]\n",
      " [  0  17  30]]\n",
      "Overall accuracy =  0.8960244648318043\n",
      "======== part by part metric ==========\n",
      "PART NUM:  16\n",
      "Confusion matrix: \n",
      "[[ 68  11   0]\n",
      " [  4 190   7]\n",
      " [  0  16  31]]\n",
      "Overall accuracy =  0.8837920489296636\n",
      "PART NUM:  26\n",
      "Confusion matrix: \n",
      "[[ 72   7   0]\n",
      " [  5 188   8]\n",
      " [  0  16  31]]\n",
      "Overall accuracy =  0.8899082568807339\n",
      "PART NUM:  36\n",
      "Confusion matrix: \n",
      "[[ 68  10   1]\n",
      " [  7 188   6]\n",
      " [  0  17  30]]\n",
      "Overall accuracy =  0.8746177370030581\n",
      "PART NUM:  46\n",
      "Confusion matrix: \n",
      "[[ 69  10   0]\n",
      " [  8 186   7]\n",
      " [  0  16  31]]\n",
      "Overall accuracy =  0.8746177370030581\n",
      "\n",
      "Current:  resnet152-TL_aug-3classes-fold1\n",
      "Confusion matrix: \n",
      "[[ 75   3   0]\n",
      " [  8 181   5]\n",
      " [  0   6  26]]\n",
      "Overall accuracy =  0.9276315789473685\n",
      "======== part by part metric ==========\n",
      "PART NUM:  16\n",
      "Confusion matrix: \n",
      "[[ 75   3   0]\n",
      " [ 14 174   6]\n",
      " [  1   9  22]]\n",
      "Overall accuracy =  0.8914473684210527\n",
      "PART NUM:  26\n",
      "Confusion matrix: \n",
      "[[ 73   4   1]\n",
      " [  6 180   8]\n",
      " [  1   6  25]]\n",
      "Overall accuracy =  0.9144736842105263\n",
      "PART NUM:  36\n",
      "Confusion matrix: \n",
      "[[ 72   6   0]\n",
      " [  3 177  14]\n",
      " [  0   9  23]]\n",
      "Overall accuracy =  0.8947368421052632\n",
      "PART NUM:  46\n",
      "Confusion matrix: \n",
      "[[ 76   2   0]\n",
      " [ 10 176   8]\n",
      " [  0  11  21]]\n",
      "Overall accuracy =  0.8980263157894737\n",
      "\n",
      "Current:  resnet152-TL_aug-3classes-fold2\n",
      "Confusion matrix: \n",
      "[[ 69  11   0]\n",
      " [  4 196   1]\n",
      " [  0   8  26]]\n",
      "Overall accuracy =  0.9238095238095239\n",
      "======== part by part metric ==========\n",
      "PART NUM:  16\n",
      "Confusion matrix: \n",
      "[[ 69  11   0]\n",
      " [  5 190   6]\n",
      " [  0  10  24]]\n",
      "Overall accuracy =  0.8984126984126984\n",
      "PART NUM:  26\n",
      "Confusion matrix: \n",
      "[[ 69  11   0]\n",
      " [  7 186   8]\n",
      " [  0   5  29]]\n",
      "Overall accuracy =  0.9015873015873016\n",
      "PART NUM:  36\n",
      "Confusion matrix: \n",
      "[[ 72   8   0]\n",
      " [  6 192   3]\n",
      " [  0  13  21]]\n",
      "Overall accuracy =  0.9047619047619048\n",
      "PART NUM:  46\n",
      "Confusion matrix: \n",
      "[[ 68  12   0]\n",
      " [  7 183  11]\n",
      " [  0   9  25]]\n",
      "Overall accuracy =  0.8761904761904762\n",
      "\n",
      "Current:  resnet152-TL_aug-3classes-fold3\n",
      "Confusion matrix: \n",
      "[[ 65  14   0]\n",
      " [  0 188  12]\n",
      " [  0   8  25]]\n",
      "Overall accuracy =  0.8910256410256411\n",
      "======== part by part metric ==========\n",
      "PART NUM:  16\n",
      "Confusion matrix: \n",
      "[[ 61  18   0]\n",
      " [  3 188   9]\n",
      " [  0   9  24]]\n",
      "Overall accuracy =  0.875\n",
      "PART NUM:  26\n",
      "Confusion matrix: \n",
      "[[ 65  14   0]\n",
      " [  2 187  11]\n",
      " [  0  13  20]]\n",
      "Overall accuracy =  0.8717948717948718\n",
      "PART NUM:  36\n",
      "Confusion matrix: \n",
      "[[ 68  11   0]\n",
      " [  3 184  13]\n",
      " [  1  11  21]]\n",
      "Overall accuracy =  0.875\n",
      "PART NUM:  46\n",
      "Confusion matrix: \n",
      "[[ 69  10   0]\n",
      " [  3 186  11]\n",
      " [  0  12  21]]\n",
      "Overall accuracy =  0.8846153846153846\n",
      "\n",
      "Current:  resnet152-TL_aug-3classes-fold4\n",
      "Confusion matrix: \n",
      "[[ 67  13   0]\n",
      " [  2 187   7]\n",
      " [  0  12  38]]\n",
      "Overall accuracy =  0.8957055214723927\n",
      "======== part by part metric ==========\n",
      "PART NUM:  16\n",
      "Confusion matrix: \n",
      "[[ 68  12   0]\n",
      " [  4 182  10]\n",
      " [  0  12  38]]\n",
      "Overall accuracy =  0.8834355828220859\n",
      "PART NUM:  26\n",
      "Confusion matrix: \n",
      "[[ 64  16   0]\n",
      " [  6 184   6]\n",
      " [  0  17  33]]\n",
      "Overall accuracy =  0.8619631901840491\n",
      "PART NUM:  36\n",
      "Confusion matrix: \n",
      "[[ 68  12   0]\n",
      " [  2 186   8]\n",
      " [  1  20  29]]\n",
      "Overall accuracy =  0.8680981595092024\n",
      "PART NUM:  46\n",
      "Confusion matrix: \n",
      "[[ 64  16   0]\n",
      " [  2 186   8]\n",
      " [  0  13  37]]\n",
      "Overall accuracy =  0.8803680981595092\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "part_list = [16, 26, 36, 46]\n",
    "exp_dir = os.path.join(pred_root, label_type)\n",
    "fold_name_list = sorted(os.listdir(exp_dir))\n",
    "\n",
    "## Overall accuracy metric\n",
    "patient_wise_overall_acc_lst = []\n",
    "part_wise_overall_acc_dic = {}\n",
    "for i_part in part_list:\n",
    "    part_wise_overall_acc_dic[i_part] = []\n",
    "\n",
    "## Confusion matrix metric\n",
    "confusion_matrix_metric_tot_lst = []\n",
    "confusion_matrix_metric_partwise_tot_dict = {}\n",
    "for i_part in part_list:\n",
    "    confusion_matrix_metric_partwise_tot_dict[i_part] = []\n",
    "    \n",
    "for i_fold_iter, i_fold_name in enumerate(fold_name_list):\n",
    "    print()\n",
    "    print('Current: ', i_fold_name)\n",
    "    \n",
    "    ## TRUE LABEL SETTING\n",
    "\n",
    "    # * Construct (personnum,true label) pair\n",
    "    true_imageset_path = os.path.join(true_dataset_root,'ImageSets','Classification','eval' + str(i_fold_iter+1) + '.txt')\n",
    "    \n",
    "    with open(true_imageset_path, 'r') as f:\n",
    "         eval_img_list = f.read().split('\\n')\n",
    "\n",
    "    person_num_list =[]\n",
    "    for i_eval_img in eval_img_list:\n",
    "        if i_eval_img == '':\n",
    "            continue\n",
    "        eval_img_info = i_eval_img.split('_')\n",
    "        age_person_num = eval_img_info[0] + '_' + eval_img_info[1] # e.g. '20_2392392' because there are three miss labeled images file name\n",
    "        if len(eval_img_info)>1: # skip blank line\n",
    "            person_num_list.append(age_person_num)\n",
    "    person_num_unique_list, unique_idx = np.unique(np.array(person_num_list), return_index=True)\n",
    "    \n",
    "    pred_by_part = {}\n",
    "    true_by_part = {}\n",
    "    for i_part in part_list:\n",
    "        pred_by_part[i_part] = []\n",
    "        true_by_part[i_part] = []\n",
    "    \n",
    "    person_num_perdiction_all_list = []\n",
    "    true_lbl_unique = []\n",
    "    \n",
    "    for i_iter, i_person_num_unique in enumerate(person_num_unique_list):\n",
    "        pred_dir = os.path.join(exp_dir, i_fold_name, 'eval_result_resnet152_cls_best_model', 'prediction_class')\n",
    "        pred_result_list = sorted(os.listdir(pred_dir))\n",
    "        pred_result_person_num = [s for s in pred_result_list if i_person_num_unique in s]\n",
    "        \n",
    "        # 하나라도 파트 없으면 false alarm!!\n",
    "        if not len(pred_result_person_num) == 4 :\n",
    "            print('Each person must have four teeth parts')\n",
    "            raise AssertionError\n",
    "            \n",
    "        # true label setting\n",
    "        true_lbl = 0\n",
    "        for i, i_pred in enumerate(pred_result_person_num):\n",
    "            true_lbl_path = os.path.join(true_lbl_dir, i_pred)\n",
    "            with open(true_lbl_path,'r') as f:\n",
    "                lbl = int(f.read())\n",
    "            if i==0:\n",
    "                true_lbl = lbl\n",
    "            else:\n",
    "                if true_lbl != lbl: # check all patients label is the same each other\n",
    "                    raise AssertionError\n",
    "                else:\n",
    "                    true_lbl = lbl\n",
    "        true_lbl_unique.append(true_lbl)\n",
    "            \n",
    "        person_num_prediction = []\n",
    "        for i_pred in pred_result_person_num:\n",
    "            pred_txt_nameOnly = os.path.splitext(i_pred)[0]\n",
    "            pred_name_info = pred_txt_nameOnly.split('_')\n",
    "            part_num = int(pred_name_info[-1])\n",
    "            pred_result_path = os.path.join(pred_dir, i_pred)\n",
    "            with open(pred_result_path, 'r') as f:\n",
    "                pred_lbl = int(f.read())\n",
    "            person_num_prediction.append(pred_lbl)\n",
    "            pred_by_part[part_num].append(pred_lbl)\n",
    "            true_by_part[part_num].append(true_lbl)\n",
    "            \n",
    "            \n",
    "        person_num_perdiction_all_list.append(person_num_prediction)\n",
    "    \n",
    "    network_final_pred_list = []\n",
    "    for i_person_num_pred in person_num_perdiction_all_list:\n",
    "        most_common_pred, num_most_common_pred = Counter(i_person_num_pred).most_common(1)[0] # 4, 6 times\n",
    "        network_final_pred_list.append(most_common_pred)\n",
    "    \n",
    "    confusion_matrix_metric = confusion_matrix(true_lbl_unique, network_final_pred_list)\n",
    "    print('Confusion matrix: ')\n",
    "    print(confusion_matrix_metric)\n",
    "    confusion_matrix_metric_tot_lst.append(confusion_matrix_metric)\n",
    "    \n",
    "    overall_acc_metric = accuracy_score(true_lbl_unique, network_final_pred_list)\n",
    "    print('Overall accuracy = ', overall_acc_metric)\n",
    "    \n",
    "    patient_wise_overall_acc_lst.append(overall_acc_metric)\n",
    "    \n",
    "    \n",
    "    ## save as excel\n",
    "    index =['True'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "    columns = ['Pred'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "    df_total = pandas.DataFrame(confusion_matrix_metric, index=index, columns = columns)\n",
    "    save_excel_path = os.path.join(exp_dir, i_fold_name, 'conf_mat_total.xlsx')\n",
    "    df_total.to_excel(save_excel_path)\n",
    "    \n",
    "    \n",
    "    print('======== part by part metric ==========')\n",
    "    for key in pred_by_part:\n",
    "        print('PART NUM: ', key)\n",
    "        confusion_matrix_metric = confusion_matrix(true_by_part[key], pred_by_part[key])\n",
    "        confusion_matrix_metric_partwise_tot_dict[key].append(confusion_matrix_metric) \n",
    "        print('Confusion matrix: ')\n",
    "        print(confusion_matrix_metric)\n",
    "        overall_acc_metric = accuracy_score(true_by_part[key], pred_by_part[key])\n",
    "        print('Overall accuracy = ', overall_acc_metric)\n",
    "        part_wise_overall_acc_dic[key].append(overall_acc_metric)\n",
    "        \n",
    "        index =['True'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "        columns = ['Pred'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "        df_part = pandas.DataFrame(confusion_matrix_metric, index=index, columns = columns)\n",
    "        save_excel_path = os.path.join(exp_dir, i_fold_name, 'conf_mat_part' + str(key) +'.xlsx')\n",
    "        df_total.to_excel(save_excel_path)\n",
    "\n",
    "confmat_save_path = os.path.join(exp_dir, '3cls_conf_mat_tot.npy')\n",
    "np.save(confmat_save_path, confusion_matrix_metric_tot_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient wise cv 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[ 69.2  10.    0. ]\n",
      " [  3.2 189.    6.2]\n",
      " [  0.   10.2  29. ]]\n",
      "\n",
      "Overall Accuracy: \n",
      "acc:  0.9068393460173461\n",
      "std_error:  0.006960749540485705\n",
      "\n",
      "Group-wise accuracy: \n",
      "Age group 1\n",
      "acc:  0.8740798442064266\n",
      "std_error:  0.02181400889329691\n",
      "\n",
      "Age group 2\n",
      "acc:  0.9524789412918576\n",
      "std_error:  0.006664949137350264\n",
      "\n",
      "Age group 3\n",
      "acc:  0.7466159024538248\n",
      "std_error:  0.025845703566582136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: ')\n",
    "confusion_matrix_metric_tot = np.array(confusion_matrix_metric_tot_lst)\n",
    "confusion_matrix_metric_avg = np.mean(confusion_matrix_metric_tot, axis = 0)\n",
    "print(confusion_matrix_metric_avg)\n",
    "print()\n",
    "print('Overall Accuracy: ')\n",
    "patient_wise_avg_acc = np.mean(patient_wise_overall_acc_lst)\n",
    "patient_wise_std_error= np.std(patient_wise_overall_acc_lst) / np.sqrt(len(patient_wise_overall_acc_lst))\n",
    "print('acc: ',patient_wise_avg_acc)\n",
    "print('std_error: ', patient_wise_std_error)\n",
    "print()\n",
    "print('Group-wise accuracy: ')\n",
    "group_wise_acc_dict={}\n",
    "for i_group in range(confusion_matrix_metric_tot.shape[1]):\n",
    "    group_wise_acc_dict[i_group] = []\n",
    "    for i_fold in range(confusion_matrix_metric_tot.shape[0]):\n",
    "        confusion_matrix_cur = confusion_matrix_metric_tot[i_fold]\n",
    "        group_wise_acc = confusion_matrix_cur[i_group, i_group] / np.sum(confusion_matrix_cur[i_group, :])\n",
    "        group_wise_acc_dict[i_group].append(group_wise_acc)\n",
    "        \n",
    "    group_wise_acc_mean = np.mean(group_wise_acc_dict[i_group])\n",
    "    group_wise_acc_std_error = np.std(group_wise_acc_dict[i_group]) / np.sqrt(len(group_wise_acc_dict[i_group]))\n",
    "    print('Age group ' + str(i_group+1))\n",
    "    print('acc: ',group_wise_acc_mean)\n",
    "    print('std_error: ',group_wise_acc_std_error)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(confusion_matrix_metric_tot_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part wise cv 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Part 16\n",
      "Confusion matrix: \n",
      "[[ 68.2  11.    0. ]\n",
      " [  6.  184.8   7.6]\n",
      " [  0.2  11.2  27.8]]\n",
      "\n",
      "Overall Accuracy: \n",
      "acc:  0.8864175397171001\n",
      "std_error:  0.003551498224208417\n",
      "\n",
      "===============\n",
      "Part 26\n",
      "Confusion matrix: \n",
      "[[ 68.6  10.4   0.2]\n",
      " [  5.2 185.    8.2]\n",
      " [  0.2  11.4  27.6]]\n",
      "\n",
      "Overall Accuracy: \n",
      "acc:  0.8879454609314965\n",
      "std_error:  0.008554809027471041\n",
      "\n",
      "===============\n",
      "Part 36\n",
      "Confusion matrix: \n",
      "[[ 69.6   9.4   0.2]\n",
      " [  4.2 185.4   8.8]\n",
      " [  0.4  14.   24.8]]\n",
      "\n",
      "Overall Accuracy: \n",
      "acc:  0.8834429286758857\n",
      "std_error:  0.006218296279121982\n",
      "\n",
      "===============\n",
      "Part 46\n",
      "Confusion matrix: \n",
      "[[ 69.2  10.    0. ]\n",
      " [  6.  183.4   9. ]\n",
      " [  0.   12.2  27. ]]\n",
      "\n",
      "Overall Accuracy: \n",
      "acc:  0.8827636023515805\n",
      "std_error:  0.0037506216507670665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i_part in part_list:\n",
    "    print('===============')\n",
    "    print('Part', i_part)\n",
    "\n",
    "    print('Confusion matrix: ')\n",
    "    confusion_matrix_metric_tot = np.array(confusion_matrix_metric_partwise_tot_dict[i_part])\n",
    "    confusion_matrix_metric_avg = np.mean(confusion_matrix_metric_tot, axis = 0)\n",
    "    print(confusion_matrix_metric_avg)\n",
    "    print()\n",
    "    print('Overall Accuracy: ')\n",
    "    part_wise_avg_acc = np.mean(part_wise_overall_acc_dic[i_part])\n",
    "    part_wise_std_error= np.std(part_wise_overall_acc_dic[i_part]) / np.sqrt(len(part_wise_overall_acc_dic[i_part]))\n",
    "    print('acc: ', part_wise_avg_acc)\n",
    "    print('std_error: ', part_wise_std_error)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient-wise, part-wise 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Patient-wise overall acc ====\n",
      "avg:  90.6839346017346\n",
      "std_error:  0.6960749540485706\n",
      "==== Part-wise overall acc ====\n",
      "Part 16\n",
      "avg:  88.64175397171002\n",
      "std_error:  0.3551498224208417\n",
      "\n",
      "Part 26\n",
      "avg:  88.79454609314965\n",
      "std_error:  0.8554809027471041\n",
      "\n",
      "Part 36\n",
      "avg:  88.34429286758856\n",
      "std_error:  0.6218296279121982\n",
      "\n",
      "Part 46\n",
      "avg:  88.27636023515805\n",
      "std_error:  0.37506216507670664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('==== Patient-wise overall acc ====')\n",
    "patient_wise_avg_acc = np.mean(patient_wise_overall_acc_lst)\n",
    "patient_wise_std_error= np.std(patient_wise_overall_acc_lst) / np.sqrt(len(patient_wise_overall_acc_lst))\n",
    "print('avg: ',patient_wise_avg_acc * 100)\n",
    "print('std_error: ', patient_wise_std_error*100)\n",
    "\n",
    "print('==== Part-wise overall acc ====')\n",
    "for i_part in part_list:\n",
    "    print('Part', i_part)\n",
    "    part_wise_avg_acc = np.mean(part_wise_overall_acc_dic[i_part])\n",
    "    part_wise_std_error= np.std(part_wise_overall_acc_dic[i_part]) / np.sqrt(len(part_wise_overall_acc_dic[i_part]))\n",
    "    print('avg: ', part_wise_avg_acc*100)\n",
    "    print('std_error: ', part_wise_std_error*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save data for using at t-test in 3cls+5cls voting\n",
    "np.save(os.path.join(exp_dir, '3cls_patient_wise_acc_lst.npy'), patient_wise_overall_acc_lst)\n",
    "for i_part in part_list:\n",
    "    out_file_name = os.path.join(exp_dir, '3cls_part'+str(i_part)+'_acc_lst.npy')\n",
    "    np.save(out_file_name, part_wise_overall_acc_dic[i_part])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient-wise acc vs part 16 acc\n",
      "p-value 0.047604806180900634\n",
      "\n",
      "Patient-wise acc vs part 26 acc\n",
      "p-value 0.163994881519845\n",
      "\n",
      "Patient-wise acc vs part 36 acc\n",
      "p-value 0.055251998034126226\n",
      "\n",
      "Patient-wise acc vs part 46 acc\n",
      "p-value 0.026109341899247403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "for i_part in part_list:\n",
    "    print('Patient-wise acc vs part ' + str(i_part) + ' acc')\n",
    "    ttest,pval = ttest_ind(patient_wise_overall_acc_lst,part_wise_overall_acc_dic[i_part])\n",
    "    print(\"p-value\", pval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient-wise acc vs part 16 acc\n",
      "p-value 0.058399271694824444\n",
      "\n",
      "Patient-wise acc vs part 26 acc\n",
      "p-value 0.16554085134479785\n",
      "\n",
      "Patient-wise acc vs part 36 acc\n",
      "p-value 0.05566042944860756\n",
      "\n",
      "Patient-wise acc vs part 46 acc\n",
      "p-value 0.033683300568934156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "for i_part in part_list:\n",
    "    print('Patient-wise acc vs part ' + str(i_part) + ' acc')\n",
    "    ttest,pval = ttest_ind(patient_wise_overall_acc_lst,part_wise_overall_acc_dic[i_part], equal_var=False)\n",
    "    print(\"p-value\",pval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
